{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fcf2/amp-bert/blob/main/Copy_of_AMP_BERT_Fine_tune_Abel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cYhGE2zhpcgo",
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PggjmYnSk0Sx",
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        },
        "id": "YxM9yut7RVvE"
      },
      "outputs": [],
      "source": [
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        },
        "id": "W_rLt8tgRVvE"
      },
      "outputs": [],
      "source": [
        "!pip install pandas scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        },
        "id": "9T06hx0lRVvF"
      },
      "outputs": [],
      "source": [
        "!pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        },
        "id": "gk37meIIRVvF"
      },
      "outputs": [],
      "source": [
        "!pip3 install torch torchvision torchaudio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        },
        "id": "K_NF6rOCRVvG"
      },
      "outputs": [],
      "source": [
        "!pip install simpletransformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8wIZMbgrdGa"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import re\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "from transformers import AutoTokenizer, Trainer, TrainingArguments, BertForSequenceClassification, AdamW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SF4XqMAEJxC7"
      },
      "outputs": [],
      "source": [
        "print(torch.version.cuda)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lb579FMwrdKU"
      },
      "outputs": [],
      "source": [
        "# define a class for the AMP data that will correctly format the sequence information\n",
        "# for fine-tuning with huggingface API\n",
        "# the input dataframe columns must be formatted the same way as the given example\n",
        "\n",
        "class amp_data():\n",
        "    def __init__(self, df, tokenizer_name='Rostlab/prot_bert_bfd', max_len=200):\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name, do_lower_case=False)\n",
        "        self.max_len = max_len\n",
        "\n",
        "        self.seqs, self.labels = self.get_seqs_labels()\n",
        "\n",
        "    def get_seqs_labels(self):\n",
        "        # isolate the amino acid sequences and their respective AMP labels\n",
        "        seqs = list(df['aa_seq'])\n",
        "        labels = list(df['AMP'].astype(int))\n",
        "\n",
        "#         assert len(seqs) == len(labels)\n",
        "        return seqs, labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        seq = \" \".join(\"\".join(self.seqs[idx].split()))\n",
        "        seq_ids = self.tokenizer(seq, truncation=True, padding='max_length', max_length=self.max_len)\n",
        "\n",
        "        sample = {key: torch.tensor(val) for key, val in seq_ids.items()}\n",
        "        sample['labels'] = torch.tensor(self.labels[idx])\n",
        "\n",
        "        return sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBymtbXgrdOc"
      },
      "outputs": [],
      "source": [
        "# read in the train dataset\n",
        "# create an amp_data class of the dataset\n",
        "\n",
        "data_url = './allAMP.csv'\n",
        "df = pd.read_csv(data_url, index_col = 0)\n",
        "df = df.sample(frac=1, random_state = 0)\n",
        "print(df.head(7))\n",
        "\n",
        "train_dataset = amp_data(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ITxp3oTs5ECd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Cargar el DataFrame desde la URL\n",
        "data_url = './allAMP.csv'\n",
        "df = pd.read_csv(data_url, index_col=0)\n",
        "\n",
        "# Mezclar los datos aleatoriamente utilizando el método frac=1 (todos los datos) y random_state para reproducibilidad\n",
        "df = df.sample(frac=1, random_state=0)\n",
        "\n",
        "# Dividir el DataFrame en conjuntos de entr'D'enamiento y evaluación (80% para entrenamiento y 20% para evaluación)\n",
        "train_df, eval_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Luego, puedes utilizar la función amp_data para preparar los datos para el entrenamiento con el modelo de lenguaje\n",
        "train_dataset = amp_data(train_df)\n",
        "eval_dataset = amp_data(eval_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "auWOqzxQRVvK"
      },
      "outputs": [],
      "source": [
        "from simpletransformers.classification import ClassificationModel\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "esILrZ9kRVvK"
      },
      "outputs": [],
      "source": [
        "# Dataset\n",
        "data_url = './allAMP.csv'\n",
        "df = pd.read_csv(data_url, index_col=0)\n",
        "df = df.sample(frac=1, random_state=0)\n",
        "train_data = pd.DataFrame(df)\n",
        "\n",
        "# prepare cross validation\n",
        "n=5\n",
        "kf = KFold(n_splits=n, random_state=42, shuffle=True)\n",
        "\n",
        "results = []\n",
        "\n",
        "#for train_index, val_index in kf.split(train_data):\n",
        "  # splitting Dataframe (dataset not included)\n",
        "    #train_df = train_data.iloc[train_index]\n",
        "    #val_df = train_data.iloc[val_index]\n",
        "    #train_dataset = amp_data(train_df)\n",
        "    #eval_dataset = amp_data(val_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4jrGQT6rdRA"
      },
      "outputs": [],
      "source": [
        "# define the necessary metrics for performance evaluation\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    #conf = confusion_matrix(labels, preds)\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        #'confusion matrix': conf\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-pQako9rdTQ"
      },
      "outputs": [],
      "source": [
        "# define the model initializing function for Trainer in huggingface\n",
        "\n",
        "def model_init():\n",
        "    return BertForSequenceClassification.from_pretrained('Rostlab/prot_bert_bfd')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kX8ZFNJmRVvM"
      },
      "outputs": [],
      "source": [
        "# set the wandb project where this run will be logged\n",
        "os.environ[\"WANDB_PROJECT\"]=\"my-awesome-project\"\n",
        "\n",
        "# save your trained model checkpoint to wandb\n",
        "os.environ[\"WANDB_LOG_MODEL\"]=\"true\"\n",
        "\n",
        "# turn off watch to log faster\n",
        "os.environ[\"WANDB_WATCH\"]=\"false\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hk0ETN8brdVR"
      },
      "outputs": [],
      "source": [
        "#@title Default title text\n",
        "# training on entire data\n",
        "# no evaluation/validation\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=5,\n",
        "    learning_rate = 2e-5,\n",
        "    per_device_train_batch_size=1,\n",
        "    warmup_steps=0,\n",
        "    weight_decay=0.1,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=100,\n",
        "    do_train=True,\n",
        "    do_eval=True,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy='epoch',\n",
        "    gradient_accumulation_steps=64,\n",
        "    fp16=True,\n",
        "    fp16_opt_level=\"O2\",\n",
        "    run_name=\"AMP-BERT\",\n",
        "    seed=0,\n",
        "    load_best_model_at_end = True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HzyjbkPi4oPY"
      },
      "outputs": [],
      "source": [
        "for train_index, val_index in kf.split(train_data):\n",
        "  # splitting Dataframe (dataset not included)\n",
        "    train_df = train_data.iloc[train_index]\n",
        "    val_df = train_data.iloc[val_index]\n",
        "    train_dataset = amp_data(train_df)\n",
        "    eval_dataset = amp_data(val_df)\n",
        "    trainer = Trainer(\n",
        "    model_init=model_init,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    compute_metrics = compute_metrics,\n",
        "    )\n",
        "    trainer.train()\n",
        "    #validate the model\n",
        "    result = trainer.evaluate(eval_dataset)\n",
        "    print(result['eval_accuracy'])\n",
        "    #append model score\n",
        "    results.append(result['eval_accuracy'])\n",
        "\n",
        "\n",
        "print(\"results\",results)\n",
        "print(f\"Mean-Precision: {sum(results) / len(results)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3MEK-Cej4sgx"
      },
      "outputs": [],
      "source": [
        "#trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SAdAeias42Px"
      },
      "outputs": [],
      "source": [
        "eval_results = trainer.evaluate(eval_dataset=eval_dataset)\n",
        "\n",
        "# Obtener el valor de la pérdida (loss) del modelo en el conjunto de evaluación\n",
        "eval_loss = eval_results['eval_loss']\n",
        "print(f\"Loss en el conjunto de evaluación: {eval_loss:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NVOmwxYarr4w"
      },
      "outputs": [],
      "source": [
        "# performance metrics on the training data itself\n",
        "\n",
        "predictions, label_ids, metrics = trainer.predict(train_dataset)\n",
        "metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3UMRG4aRVvQ"
      },
      "outputs": [],
      "source": [
        "predictions, label_ids, metrics = trainer.predict(eval_dataset)\n",
        "metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6JgOpbw9q4Y"
      },
      "outputs": [],
      "source": [
        "# save the model, if desired\n",
        "\n",
        "trainer.save_model('./Fine-tuned_model_Gaby_dados_crossValidation/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqdIvYee4i_v"
      },
      "outputs": [],
      "source": [
        "# predict AMP/non-AMP for a single example\n",
        "\n",
        "# load appropriate tokenizer and fine-tuned model\n",
        "tokenizer = AutoTokenizer.from_pretrained('Rostlab/prot_bert_bfd', do_lower_case=False)\n",
        "model = BertForSequenceClassification.from_pretrained(\"./Fine-tuned_model_Gaby_dados_crossValidation\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqezWrC8-WWa"
      },
      "source": [
        "--------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3q3GujE3_csL"
      },
      "outputs": [],
      "source": [
        "# predict AMP/non-AMP for a single example (default ex. is from external test data: DRAMP00126)\n",
        "\n",
        "#@markdown **Input peptide sequence (upper case only)**\n",
        "input_seq = 'GILSDFMGMVA' #@param {type:\"string\"}\n",
        "input_seq_spaced = ' '.join([ input_seq[i:i+1] for i in range(0, len(input_seq), 1) ])\n",
        "input_seq_spaced = re.sub(r'[UZOB]', 'X', input_seq_spaced)\n",
        "input_seq_tok = tokenizer(input_seq_spaced, return_tensors = 'pt')\n",
        "\n",
        "output = model(**input_seq_tok)\n",
        "logits = output[0]\n",
        "\n",
        "# extract AMP class probability and make binary prediction\n",
        "y_prob = torch.sigmoid(logits)[:,1].detach().numpy()\n",
        "y_pred = y_prob > 0.5\n",
        "if y_pred == True:\n",
        "  input_class = 'AMP'\n",
        "else:\n",
        "  input_class = 'non-AMP'\n",
        "print(y_pred)\n",
        "print(y_prob)\n",
        "print('Input peptide sequence: ' + input_seq)\n",
        "print('Class prediction: ' + input_class)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awfCfwkNSPZ8"
      },
      "source": [
        "------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsq-R25Ty7xq"
      },
      "source": [
        "MASK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZgTQtX6zC9W"
      },
      "outputs": [],
      "source": [
        "#!apt install git-lfs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2P4Y06Xzr8q"
      },
      "outputs": [],
      "source": [
        "# read in the train dataset\n",
        "# create an amp_data class of the dataset\n",
        "\n",
        "data_url2 = './AMP_cdhit.csv'\n",
        "df = pd.read_csv(data_url2, index_col = 0)\n",
        "df = df.sample(frac=1, random_state = 0)\n",
        "print(df.head(7))\n",
        "\n",
        "train_dataset2 = amp_data(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7rVjQcP9RVvZ"
      },
      "outputs": [],
      "source": [
        "# Dataset\n",
        "data_url = './AMP_cdhit.csv'\n",
        "df = pd.read_csv(data_url, index_col=0)\n",
        "train_data = pd.DataFrame(df)\n",
        "\n",
        "# prepare cross validation\n",
        "n=5\n",
        "kf = KFold(n_splits=n, random_state=42, shuffle=True)\n",
        "\n",
        "results = []\n",
        "\n",
        "for train_index, val_index in kf.split(train_data):\n",
        "  # splitting Dataframe (dataset not included)\n",
        "    train_df = train_data.iloc[train_index]\n",
        "    val_df = train_data.iloc[val_index]\n",
        "\n",
        "train_dataset2 = amp_data(train_df)\n",
        "eval_dataset2 = amp_data(val_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3PEEOkmT17Pw"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForMaskedLM\n",
        "model2 = AutoModelForMaskedLM.from_pretrained('Rostlab/prot_bert_bfd')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pjTI_NzwwfV8"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7TVfpaFl3ZX6"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('Rostlab/prot_bert_bfd', do_lower_case=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mRTLQgOu2zeV"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForLanguageModeling\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7yxNUxil4Cld"
      },
      "outputs": [],
      "source": [
        "model_checkpoint = 'Rostlab/prot_bert_bfd'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9o9B7fIq1tXc"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=5,\n",
        "    learning_rate = 2e-5,\n",
        "    per_device_train_batch_size=2,\n",
        "    warmup_steps=0,\n",
        "    weight_decay=0.1,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=100,\n",
        "    do_train=True,\n",
        "    do_eval=True,\n",
        "    evaluation_strategy=\"no\",\n",
        "    save_strategy='no',\n",
        "    gradient_accumulation_steps=64,\n",
        "    fp16=True,\n",
        "    fp16_opt_level=\"O2\",\n",
        "    run_name=\"AMP-BERT_MASK\",\n",
        "    seed=0,\n",
        "    load_best_model_at_end = True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d5ObCeTN2ywM"
      },
      "outputs": [],
      "source": [
        "trainer2 = Trainer(\n",
        "    model=model2,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset2,\n",
        "    eval_dataset=eval_dataset2,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics = compute_metrics,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iyFt0GWV4_J4"
      },
      "outputs": [],
      "source": [
        "trainer2.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "omMqGo_BHKYU"
      },
      "outputs": [],
      "source": [
        "# save the model, if desired\n",
        "\n",
        "trainer2.save_model('./Fine-tuned_MASK3_model_Gaby_dataset/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K1jBTZUTHd1w"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForMaskedLM\n",
        "\n",
        "model_mask = AutoModelForMaskedLM.from_pretrained(\"./Fine-tuned_MASK3_model_Gaby_dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_CRJAYQfROFa"
      },
      "outputs": [],
      "source": [
        "from transformers import BertForMaskedLM, BertTokenizer, pipeline\n",
        "tokenizer = BertTokenizer.from_pretrained('Rostlab/prot_bert_bfd', do_lower_case=False )\n",
        "#model_mask = BertForMaskedLM.from_pretrained(\"Rostlab/prot_bert_bfd\")\n",
        "unmasker = pipeline('fill-mask', model=model_mask, tokenizer=tokenizer)\n",
        "unmasker('G Q A D [MASK] I L K A L G')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yj5mPwDM-b5x"
      },
      "outputs": [],
      "source": [
        "from transformers import BertForMaskedLM, BertTokenizer, pipeline\n",
        "#tokenizer = BertTokenizer.from_pretrained('Rostlab/prot_bert_bfd', do_lower_case=False )\n",
        "model_mask2 = BertForMaskedLM.from_pretrained(\"Rostlab/prot_bert_bfd\")\n",
        "unmasker = pipeline('fill-mask', model=model_mask2, tokenizer=tokenizer)\n",
        "unmasker('G Q A D [MASK] I L K A L G')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kBrAB6WcEl2"
      },
      "source": [
        "-----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-VR5ZMvSOmC"
      },
      "source": [
        "Predict multiple peptides"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y2y0CmuYpyY0"
      },
      "outputs": [],
      "source": [
        "# Open the file containing the FASTA-formatted list of words\n",
        "with open(\"new_desing8.fasta\", \"r\") as file:\n",
        "\n",
        "    # Read in the contents of the file as a string\n",
        "    file_contents = file.read()\n",
        "\n",
        "    # Split the contents into separate sequences\n",
        "    sequences = file_contents.split(\">\")[1:]\n",
        "\n",
        "    # Iterate over each sequence and extract the sequence ID and nucleotide sequence\n",
        "    for seq in sequences:\n",
        "        seq_id, *seq_lines = seq.split(\"\\n\")\n",
        "        seq = \"\".join(seq_lines)\n",
        "\n",
        "        seq_spaced = ' '.join([ seq[i:i+1] for i in range(0, len(seq), 1) ])\n",
        "        seq_spaced = re.sub(r'[UZOB]', 'X', seq_spaced)\n",
        "        seq_tok = tokenizer(seq_spaced, return_tensors = 'pt')\n",
        "\n",
        "        output = model(**seq_tok)\n",
        "        logits = output[0]\n",
        "\n",
        "        # extract AMP class probability and make binary prediction\n",
        "        y_prob = torch.sigmoid(logits)[:,1].detach().numpy()\n",
        "        y_pred = y_prob > 0.5\n",
        "        if y_pred == True:\n",
        "           input_class = 'AMP'\n",
        "        else:\n",
        "           input_class = 'non-AMP'\n",
        "        #print(y_pred)\n",
        "        print(y_prob)\n",
        "        #print('Input peptide sequence: ' + seq)\n",
        "        #print('Class prediction: ' + input_class)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WM5xxK2oASL8"
      },
      "source": [
        "-------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NxKuqYb77QmT",
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "!pip install lime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JnSQ18uy5zJb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import lime\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from lime.lime_text import LimeTextExplainer\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "szxCwx_1RVvl"
      },
      "outputs": [],
      "source": [
        "class_names = ['positive','negative', 'neutral']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-B-dbI1VRVvm"
      },
      "outputs": [],
      "source": [
        "def predictor(texts):\n",
        "    outputs = model(**tokenizer(texts, return_tensors=\"pt\", padding=True))\n",
        "    probas = F.softmax(outputs.logits).detach().numpy()\n",
        "    return probas\n",
        "\n",
        "explainer = LimeTextExplainer(class_names=class_names)\n",
        "\n",
        "input_seq_spaced = 'G L F S T V K G I L K'\n",
        "exp = explainer.explain_instance(input_seq_spaced, predictor, num_features=11)\n",
        "exp.show_in_notebook(text=input_seq_spaced)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jn9yRwUNkJgx"
      },
      "source": [
        "--------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3oNi8FduRVvn"
      },
      "outputs": [],
      "source": [
        "input_seq_spaced = 'G L F S T V K G I L K'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRA317udRVvn"
      },
      "outputs": [],
      "source": [
        "pipe = TextClassificationPipeline(model=model, tokenizer=tokenizer, return_all_scores=True)\n",
        "print(pipe([input_seq_spaced]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Xbid0OPRVvn"
      },
      "outputs": [],
      "source": [
        "from lime.lime_text import LimeTextExplainer\n",
        "explainer = LimeTextExplainer(class_names=class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sEvhgYbIRVvo"
      },
      "outputs": [],
      "source": [
        "exp = explainer.explain_instance(input_seq_spaced, pipe, num_features=6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wuWoClYhRVvo"
      },
      "outputs": [],
      "source": [
        "exp.show_in_notebook(text=input_seq_spaced)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mon7pVlvQta"
      },
      "source": [
        "### Applying transformers interpret"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BOx186-pRFy"
      },
      "source": [
        "---------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEs1MCKduJog"
      },
      "source": [
        "----------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anCkOkyIj62K"
      },
      "source": [
        "**SHAP**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HqBbXcNlNgbj",
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "#!pip install --quiet shap==0.39\n",
        "!pip install shap\n",
        "!pip install xformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        },
        "id": "-731e3IlRVvq"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade Numba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        },
        "id": "hRexqnvmRVvq"
      },
      "outputs": [],
      "source": [
        "!pip install NumPy==1.23"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VPKshTu5RVvq"
      },
      "outputs": [],
      "source": [
        "import shap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wwexmw6RVvq"
      },
      "outputs": [],
      "source": [
        "\n",
        "import transformers\n",
        "\n",
        "from transformers import (AutoTokenizer,\n",
        "                          AutoModelForSequenceClassification,\n",
        "                          TextClassificationPipeline)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-A7n4N_oirzf"
      },
      "outputs": [],
      "source": [
        "pipe = TextClassificationPipeline(model=model, tokenizer=tokenizer, return_all_scores=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zx4AKkFijGcy"
      },
      "outputs": [],
      "source": [
        "def score_and_visualize(text):\n",
        "  prediction = pipe([text])\n",
        "  print(prediction[0])\n",
        "\n",
        "  explainer = shap.Explainer(pipe)\n",
        "  shap_values = explainer([text])\n",
        "\n",
        "  shap.plots.text(shap_values)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tcFWpG99jLmZ"
      },
      "outputs": [],
      "source": [
        "score_and_visualize(input_seq_spaced)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZuWk8xjzy6F"
      },
      "source": [
        "-----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0t4H1q7yV0G"
      },
      "outputs": [],
      "source": [
        "model_gpu = model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tEgByM1JRVvs"
      },
      "outputs": [],
      "source": [
        "labels = [x[0] for x in sorted(model.config.label2id.items(), key=lambda x: x[1])]\n",
        "\n",
        "def model_prediction_gpu(x):\n",
        "    tv = torch.tensor([tokenizer.encode(v, padding='max_length',\n",
        "                                        max_length=512, truncation=True) for v in x]).cuda()\n",
        "    attention_mask = (tv!=0).type(torch.int64).cuda()\n",
        "    outputs = model_gpu(tv, attention_mask=attention_mask)[0]\n",
        "    scores = torch.nn.Softmax(dim=-1)(outputs)\n",
        "    val = torch.logit(scores).detach().cpu().numpy()\n",
        "\n",
        "    return val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HG-0YiebzzlS"
      },
      "outputs": [],
      "source": [
        "gpu_explainer = shap.Explainer(model_prediction_gpu, tokenizer, output_names=labels)\n",
        "\n",
        "shap_values = gpu_explainer(\n",
        "    [input_seq_spaced]\n",
        ")\n",
        "\n",
        "output = shap.plots.text(shap_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSc494ju7pm3"
      },
      "source": [
        "--------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2mt4GJ6LGiiE",
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "!pip install transformers_interpret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zGSupC7nGZaE"
      },
      "outputs": [],
      "source": [
        "from transformers_interpret import MultiLabelClassificationExplainer\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l5Pac5jTynir"
      },
      "outputs": [],
      "source": [
        "# With both the model and tokenizer initialized we are now able to get explanations on an example text.\n",
        "cls_explainer = MultiLabelClassificationExplainer(model, tokenizer)\n",
        "\n",
        "word_attributions = cls_explainer(input_seq_spaced)\n",
        "\n",
        "# show output\n",
        "word_attributions\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5SfCQZVpTFQC"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}